{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"cd '/kaggle/working'","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:39:02.746553Z","iopub.execute_input":"2021-11-27T15:39:02.747112Z","iopub.status.idle":"2021-11-27T15:39:02.767905Z","shell.execute_reply.started":"2021-11-27T15:39:02.747016Z","shell.execute_reply":"2021-11-27T15:39:02.767037Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport pathlib\n# Clone the tensorflow models repository if it doesn't already exist\nif \"models\" in pathlib.Path.cwd().parts:\n  while \"models\" in pathlib.Path.cwd().parts:\n    os.chdir('..')\nelif not pathlib.Path('models').exists():\n  !git clone --depth 1 https://github.com/tensorflow/models","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:39:20.676656Z","iopub.execute_input":"2021-11-27T15:39:20.676913Z","iopub.status.idle":"2021-11-27T15:39:24.319791Z","shell.execute_reply.started":"2021-11-27T15:39:20.676883Z","shell.execute_reply":"2021-11-27T15:39:24.318892Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"%cd models/research/\n!protoc object_detection/protos/*.proto --python_out=.\n!cp object_detection/packages/tf2/setup.py .\n!python -m pip install --use-deprecated=legacy-resolver .","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:41:24.411605Z","iopub.execute_input":"2021-11-27T15:41:24.412416Z","iopub.status.idle":"2021-11-27T15:43:01.378686Z","shell.execute_reply.started":"2021-11-27T15:41:24.412369Z","shell.execute_reply":"2021-11-27T15:43:01.377644Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip uninstall tensorflow-gpu -y\n!pip uninstall tensorflow -y\n!pip install tensorflow-gpu==2.4.1","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:43:46.347013Z","iopub.execute_input":"2021-11-27T15:43:46.347791Z","iopub.status.idle":"2021-11-27T15:44:34.038088Z","shell.execute_reply.started":"2021-11-27T15:43:46.347737Z","shell.execute_reply":"2021-11-27T15:44:34.037205Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport os\nimport random\nimport io\nimport imageio\nimport glob\nimport scipy.misc\nimport numpy as np\nfrom six import BytesIO\nfrom PIL import Image, ImageDraw, ImageFont\nfrom IPython.display import display, Javascript\nfrom IPython.display import Image as IPyImage\n\nimport tensorflow as tf\n\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import config_util\nfrom object_detection.utils import visualization_utils as viz_utils\n#from object_detection.utils import colab_utils\nfrom object_detection.builders import model_builder\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:45:08.147152Z","iopub.execute_input":"2021-11-27T15:45:08.147960Z","iopub.status.idle":"2021-11-27T15:45:11.833589Z","shell.execute_reply.started":"2021-11-27T15:45:08.147920Z","shell.execute_reply":"2021-11-27T15:45:11.832749Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:45:30.407307Z","iopub.execute_input":"2021-11-27T15:45:30.407917Z","iopub.status.idle":"2021-11-27T15:45:30.418416Z","shell.execute_reply.started":"2021-11-27T15:45:30.407858Z","shell.execute_reply":"2021-11-27T15:45:30.417585Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!python ./object_detection/builders/model_builder_tf2_test.py","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:45:37.587028Z","iopub.execute_input":"2021-11-27T15:45:37.587777Z","iopub.status.idle":"2021-11-27T15:46:12.351843Z","shell.execute_reply.started":"2021-11-27T15:45:37.587736Z","shell.execute_reply":"2021-11-27T15:46:12.350977Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!pip install untangle","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:46:43.207232Z","iopub.execute_input":"2021-11-27T15:46:43.207521Z","iopub.status.idle":"2021-11-27T15:46:52.397662Z","shell.execute_reply.started":"2021-11-27T15:46:43.207488Z","shell.execute_reply":"2021-11-27T15:46:52.396804Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"cd '../'","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:48:46.286090Z","iopub.execute_input":"2021-11-27T15:48:46.286674Z","iopub.status.idle":"2021-11-27T15:48:46.291812Z","shell.execute_reply.started":"2021-11-27T15:48:46.286636Z","shell.execute_reply":"2021-11-27T15:48:46.291069Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"len(os.listdir('../input/bccd-dataset/BCCD/JPEGImages'))","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:48:48.306740Z","iopub.execute_input":"2021-11-27T15:48:48.307422Z","iopub.status.idle":"2021-11-27T15:48:48.358492Z","shell.execute_reply.started":"2021-11-27T15:48:48.307383Z","shell.execute_reply":"2021-11-27T15:48:48.357799Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import PIL\nimport tensorflow as tf\nimport hashlib\nimport io\nimport os\nimport untangle\nfrom object_detection.utils import dataset_util\n\ndef xml_to_tf_example(xml_obj):\n    label_map_dict = {'WBC':1 , 'RBC':2 , 'Platelets':3}\n    filename = xml_obj.annotation.filename.cdata\n    full_path = '../input/bccd-dataset/BCCD/JPEGImages/' + filename\n    with tf.io.gfile.GFile(full_path, 'rb') as fid:\n        encoded_jpg = fid.read()\n    encoded_jpg_io = io.BytesIO(encoded_jpg)\n    image = PIL.Image.open(encoded_jpg_io)\n    if image.format != 'JPEG':\n        raise ValueError('Image format not JPEG')\n    key = hashlib.sha256(encoded_jpg).hexdigest()\n\n    width = int(xml_obj.annotation.size.width.cdata)\n    height = int(xml_obj.annotation.size.height.cdata)\n\n    xmin = []\n    ymin = []\n    xmax = []\n    ymax = []\n\n    classes = []\n    classes_text = []\n    truncated = []\n\n    for obj in xml_obj.annotation.object:\n\n        xmin.append(float(obj.bndbox.xmin.cdata) / width)\n        ymin.append(float(obj.bndbox.ymin.cdata) / height)\n        xmax.append(float(obj.bndbox.xmax.cdata) / width)\n        ymax.append(float(obj.bndbox.ymax.cdata) / height)\n        classes_text.append(obj.name.cdata.encode('utf8'))\n        classes.append(label_map_dict[obj.name.cdata])\n        truncated.append(int(obj.truncated.cdata))\n    #print(width)\n    #print(xmin)\n    example = tf.train.Example(features=tf.train.Features(feature={\n        'image/height': dataset_util.int64_feature(height),\n        'image/width': dataset_util.int64_feature(width),\n        'image/filename': dataset_util.bytes_feature(filename.encode('utf8')),\n        'image/source_id': dataset_util.bytes_feature(filename.encode('utf8')),\n        'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n        'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n        'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n        'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n        'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n        'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n        'image/object/class/label': dataset_util.int64_list_feature(classes),\n        'image/object/truncated': dataset_util.int64_list_feature(truncated),\n    }))\n    return example\n\ndata_dir = '../input/bccd-dataset/BCCD'\n\ntfrecord_path = './train.tfrecord'\ni = 0\nwriter = tf.io.TFRecordWriter(tfrecord_path)\n\nannotations_dir = os.path.join(data_dir, 'Annotations')\nexamples_list = os.listdir(annotations_dir)\nfor idx, example in enumerate(examples_list):\n    if(i>300):\n        break\n    if example.endswith('.xml'):\n        path = os.path.join(annotations_dir, example)\n        xml_obj = untangle.parse(path)\n        tf_example = xml_to_tf_example(xml_obj)\n        writer.write(tf_example.SerializeToString())\n    i+=1\n        \n\nwriter.close()","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:50:35.288718Z","iopub.execute_input":"2021-11-27T15:50:35.289020Z","iopub.status.idle":"2021-11-27T15:50:37.512424Z","shell.execute_reply.started":"2021-11-27T15:50:35.288988Z","shell.execute_reply":"2021-11-27T15:50:37.511632Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"%%writefile ./label_map.pbtxt\nitem {\n  id: 1\n  name: 'RBC'\n}\nitem {\n  id: 2\n  name: 'WBC'\n}\nitem {\n  id: 3\n  name: 'Platelets'\n}","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:50:54.310664Z","iopub.execute_input":"2021-11-27T15:50:54.311339Z","iopub.status.idle":"2021-11-27T15:50:54.319422Z","shell.execute_reply.started":"2021-11-27T15:50:54.311293Z","shell.execute_reply":"2021-11-27T15:50:54.318502Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"MODELS_CONFIG = {\n        'faster_rcnn_resnet50': {\n        'model_name': 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8',\n        'base_pipeline_file': 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config',\n        'pretrained_checkpoint': 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz',\n        'batch_size': 4\n    },\n\n}\n\n#in this tutorial we implement the lightweight, smallest state of the art efficientdet model\n#if you want to scale up tot larger efficientdet models you will likely need more compute!\nchosen_model = 'faster_rcnn_resnet50'\n\nnum_steps = 3000 #The more steps, the longer the training. Increase if your loss function is still decreasing and validation metrics are increasing. \nnum_eval_steps = 500 #Perform evaluation after so many steps\n\nmodel_name = MODELS_CONFIG[chosen_model]['model_name']\npretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\nbase_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\nbatch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your training","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:51:59.812422Z","iopub.execute_input":"2021-11-27T15:51:59.812684Z","iopub.status.idle":"2021-11-27T15:51:59.818312Z","shell.execute_reply.started":"2021-11-27T15:51:59.812654Z","shell.execute_reply":"2021-11-27T15:51:59.817603Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"%mkdir ./models/research/deploy/\n%cd ./models/research/deploy/\nimport tarfile\ndownload_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n\n!wget {download_tar}\ntar = tarfile.open(pretrained_checkpoint)\ntar.extractall()\ntar.close()","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:52:04.121479Z","iopub.execute_input":"2021-11-27T15:52:04.122009Z","iopub.status.idle":"2021-11-27T15:52:08.759972Z","shell.execute_reply.started":"2021-11-27T15:52:04.121971Z","shell.execute_reply":"2021-11-27T15:52:08.759165Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/models/research/deploy\ndownload_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n!wget {download_config}","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:52:09.211698Z","iopub.execute_input":"2021-11-27T15:52:09.214288Z","iopub.status.idle":"2021-11-27T15:52:10.051345Z","shell.execute_reply.started":"2021-11-27T15:52:09.214244Z","shell.execute_reply":"2021-11-27T15:52:10.050520Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"pipeline_fname = '/kaggle/working/models/research/deploy/' + base_pipeline_file\nfine_tune_checkpoint = '/kaggle/working/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\nnum_classes = 3","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:52:18.522413Z","iopub.execute_input":"2021-11-27T15:52:18.522708Z","iopub.status.idle":"2021-11-27T15:52:18.527342Z","shell.execute_reply.started":"2021-11-27T15:52:18.522673Z","shell.execute_reply":"2021-11-27T15:52:18.526559Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"cd '../'","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:52:37.901426Z","iopub.execute_input":"2021-11-27T15:52:37.902048Z","iopub.status.idle":"2021-11-27T15:52:37.907592Z","shell.execute_reply.started":"2021-11-27T15:52:37.902005Z","shell.execute_reply":"2021-11-27T15:52:37.906472Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import re\n\n#%cd /kaggle/working/models/research/deploy\nprint('writing custom configuration file')\n\nwith open(pipeline_fname) as f:\n    s = f.read()\nwith open('pipeline_file.config', 'w') as f:\n    \n    # fine_tune_checkpoint\n    s = re.sub('fine_tune_checkpoint: \".*?\"',\n               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n    \n    # tfrecord files train and test.\n    s = re.sub(\n        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format('./train.tfrecord'), s)\n    s = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format('./test.tfrecord'), s)\n\n    # label_map_path\n    s = re.sub('label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format('./label_map.pbtxt'), s)\n\n    # Set training batch_size.\n    s = re.sub('batch_size: [0-9]+',\n               'batch_size: {}'.format(batch_size), s)\n\n    # Set training steps, num_steps\n    s = re.sub('num_steps: [0-9]+',\n               'num_steps: {}'.format(num_steps), s)\n    \n    # Set number of classes num_classes.\n    s = re.sub('num_classes: [0-9]+',\n               'num_classes: {}'.format(num_classes), s)\n    \n    #fine-tune checkpoint type\n    s = re.sub(\n        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n        \n    f.write(s)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:52:48.042262Z","iopub.execute_input":"2021-11-27T15:52:48.042545Z","iopub.status.idle":"2021-11-27T15:52:48.053205Z","shell.execute_reply.started":"2021-11-27T15:52:48.042514Z","shell.execute_reply":"2021-11-27T15:52:48.052462Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"%cat pipeline_file.config","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:52:52.581462Z","iopub.execute_input":"2021-11-27T15:52:52.581720Z","iopub.status.idle":"2021-11-27T15:52:53.283418Z","shell.execute_reply.started":"2021-11-27T15:52:52.581690Z","shell.execute_reply":"2021-11-27T15:52:53.282580Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"pipeline_file = '/kaggle/working/pipeline_file.config'\nmodel_dir = '/kaggle/working/training/'","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:53:05.172736Z","iopub.execute_input":"2021-11-27T15:53:05.173027Z","iopub.status.idle":"2021-11-27T15:53:05.179728Z","shell.execute_reply.started":"2021-11-27T15:53:05.172991Z","shell.execute_reply":"2021-11-27T15:53:05.178755Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"!python /kaggle/working/models/research/object_detection/model_main_tf2.py \\\n    --pipeline_config_path={pipeline_file} \\\n    --model_dir={model_dir} \\\n    --alsologtostderr \\\n    --num_train_steps={num_steps} \\\n    --sample_1_of_n_eval_examples=1 \\\n    --num_eval_steps={num_eval_steps}","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:53:08.401335Z","iopub.execute_input":"2021-11-27T15:53:08.401607Z","iopub.status.idle":"2021-11-27T16:11:28.406623Z","shell.execute_reply.started":"2021-11-27T15:53:08.401576Z","shell.execute_reply":"2021-11-27T16:11:28.405779Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def load_image_into_numpy_array(path):\n  \"\"\"Load an image from file into a numpy array.\n\n  Puts image into numpy array to feed into tensorflow graph.\n  Note that by convention we put it into a numpy array with shape\n  (height, width, channels), where channels=3 for RGB.\n\n  Args:\n    path: the file path to the image\n\n  Returns:\n    uint8 numpy array with shape (img_height, img_width, 3)\n  \"\"\"\n  img_data = tf.io.gfile.GFile(path, 'rb').read()\n  image = Image.open(BytesIO(img_data))\n  (im_width, im_height) = image.size\n  return np.array(image.getdata()).reshape(\n      (im_height, im_width, 3)).astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T16:11:38.747168Z","iopub.execute_input":"2021-11-27T16:11:38.747955Z","iopub.status.idle":"2021-11-27T16:11:38.754380Z","shell.execute_reply.started":"2021-11-27T16:11:38.747904Z","shell.execute_reply":"2021-11-27T16:11:38.753209Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"%ls './training/'","metadata":{"execution":{"iopub.status.busy":"2021-11-27T16:11:44.331728Z","iopub.execute_input":"2021-11-27T16:11:44.331992Z","iopub.status.idle":"2021-11-27T16:11:45.007188Z","shell.execute_reply.started":"2021-11-27T16:11:44.331960Z","shell.execute_reply":"2021-11-27T16:11:45.006284Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"import pathlib\n\nfilenames = list(pathlib.Path('./training/').glob('*.index'))\n\nfilenames.sort()\nprint(filenames)\n\n#recover our saved model\npipeline_config = pipeline_file\n#generally you want to put the last ckpt from training in here\nmodel_dir = str(filenames[-1]).replace('.index','')\nconfigs = config_util.get_configs_from_pipeline_file(pipeline_config)\nmodel_config = configs['model']\ndetection_model = model_builder.build(\n      model_config=model_config, is_training=False)\n\n# Restore checkpoint\nckpt = tf.compat.v2.train.Checkpoint(\n      model=detection_model)\nckpt.restore(os.path.join(str(filenames[-1]).replace('.index','')))\n\n\ndef get_model_detection_function(model):\n  \"\"\"Get a tf.function for detection.\"\"\"\n\n  @tf.function\n  def detect_fn(image):\n    \"\"\"Detect objects in image.\"\"\"\n\n    image, shapes = model.preprocess(image)\n    prediction_dict = model.predict(image, shapes)\n    detections = model.postprocess(prediction_dict, shapes)\n\n    return detections, prediction_dict, tf.reshape(shapes, [-1])\n\n  return detect_fn\n\ndetect_fn = get_model_detection_function(detection_model)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T16:11:55.661686Z","iopub.execute_input":"2021-11-27T16:11:55.662352Z","iopub.status.idle":"2021-11-27T16:11:56.678388Z","shell.execute_reply.started":"2021-11-27T16:11:55.662303Z","shell.execute_reply":"2021-11-27T16:11:56.677582Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"label_map_path = configs['eval_input_config'].label_map_path\nlabel_map = label_map_util.load_labelmap(label_map_path)\ncategories = label_map_util.convert_label_map_to_categories(\n    label_map,\n    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n    use_display_name=True)\ncategory_index = label_map_util.create_category_index(categories)\nlabel_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T16:12:02.732546Z","iopub.execute_input":"2021-11-27T16:12:02.732806Z","iopub.status.idle":"2021-11-27T16:12:02.739675Z","shell.execute_reply.started":"2021-11-27T16:12:02.732776Z","shell.execute_reply":"2021-11-27T16:12:02.738502Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import random\nimport matplotlib.patches as patches\ndata_dir = '../input/bccd-dataset/BCCD'\nannotations_dir = os.path.join(data_dir, 'Annotations')\nexamples_list = os.listdir(annotations_dir)\npath = os.path.join(annotations_dir, 'BloodImage_00360.xml')\n#print(path)\nxml_obj = untangle.parse(path)\nlst1 = []\nfor obj in xml_obj.annotation.object:\n    lst2 = []\n    lst2.append(float(obj.bndbox.xmin.cdata))\n    lst2.append(float(obj.bndbox.ymin.cdata))\n    lst2.append(float(obj.bndbox.xmax.cdata))\n    lst2.append(float(obj.bndbox.ymax.cdata))\n    lst1.append(lst2)\n\nplt.figure(figsize=(6,6))\nplt.imshow(load_image_into_numpy_array('../input/bccd-dataset/BCCD/JPEGImages/BloodImage_00360.jpg'))\nax = plt.gca()\n#fig, ax = plt.subplots()\n#ax.imshow(image_np_with_detections)\nfor i in lst1:\n    rect = patches.Rectangle((i[0],i[1]), (i[2]-i[0]) , (i[3]-i[1]), linewidth=1, edgecolor='r', facecolor='none')\n    ax.add_patch(rect)\nplt.show()\nplt.savefig('Original_360_SSD_ResNet50_V1_FPN_640x640.jpeg')","metadata":{"execution":{"iopub.status.busy":"2021-11-27T16:37:06.696056Z","iopub.execute_input":"2021-11-27T16:37:06.696863Z","iopub.status.idle":"2021-11-27T16:37:07.648892Z","shell.execute_reply.started":"2021-11-27T16:37:06.696820Z","shell.execute_reply":"2021-11-27T16:37:07.648076Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"def draw_bbox(image, box, label, color):   \n    alpha = 0.1\n    alpha_box = 0.4\n    overlay_bbox = image.copy()\n    overlay_text = image.copy()\n    output = image.copy()\n    output = cv2.rectangle(output, (box[0], box[1]), (box[2], box[3]),color, 2)\n    text_width, text_height = cv2.getTextSize(label.upper(), cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)[0]\n    cv2.rectangle(overlay_bbox, (box[0], box[1]), (box[2], box[3]),color, -1)\n    cv2.addWeighted(overlay_bbox, alpha, output, 1 - alpha, 0, output)\n    cv2.rectangle(overlay_text, (box[0], box[1]-7-text_height),(box[0]+text_width+2, box[1]), (0, 0, 0), -1)\n    cv2.addWeighted(overlay_text, alpha_box, output, 1 - alpha_box, 0, output)\n    cv2.putText(output, label.upper(), (box[0], box[1]-5),cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n    return output","metadata":{"execution":{"iopub.status.busy":"2021-11-27T16:15:02.042443Z","iopub.execute_input":"2021-11-27T16:15:02.043036Z","iopub.status.idle":"2021-11-27T16:15:02.052880Z","shell.execute_reply.started":"2021-11-27T16:15:02.042976Z","shell.execute_reply":"2021-11-27T16:15:02.051985Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import random\nimport matplotlib.patches as patches\nimport cv2 \n\nlabel2color = [[59, 238, 119], [222, 21, 229], [94, 49, 164], [206, 221, 133], [117, 75, 3],\n                 [210, 224, 119], [211, 176, 166], [63, 7, 197], [102, 65, 77], [194, 134, 175],\n                 [209, 219, 50], [255, 44, 47], [89, 125, 149], [110, 27, 100]]\n\nTEST_IMAGE_PATHS = os.listdir('../input/bccd-dataset/BCCD/JPEGImages')\nimage_path = '../input/bccd-dataset/BCCD/JPEGImages/BloodImage_00360.jpg'\n#print(image_path)\nimage_np = load_image_into_numpy_array(image_path)\n\ninput_tensor = tf.convert_to_tensor(\n    np.expand_dims(image_np, 0), dtype=tf.float32)\ndetections, predictions_dict, shapes = detect_fn(input_tensor)\n#print(detections)\n#print(predictions_dict)\nlabel_id_offset = 1\nimage_np_with_detections = image_np.copy()\nmin_score_thresh = 0.2\nwidth, height, _ = image_np.shape\nboxes = detections['detection_boxes'][0].numpy()\nboxes = boxes[:,[1, 0, 3, 2]]*np.array([height, width, height, width])\n\nfor box, label_id, score in zip(boxes,(detections['detection_classes'][0].numpy() + label_id_offset).astype(int),detections['detection_scores'][0].numpy()):\n    if (score > min_score_thresh):\n        image_np_with_detections = draw_bbox(image_np_with_detections, list(np.int_(box)),category_index[label_id]['name']+'_'+str(round(score*100,1))+'%',label2color[label_id-1])\n\n#viz_utils.visualize_boxes_and_labels_on_image_array(\n#      image_np_with_detections,\n#      detections['detection_boxes'][0].numpy(),\n#      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n#      detections['detection_scores'][0].numpy(),\n#      category_index,\n#      use_normalized_coordinates=True,\n#      max_boxes_to_draw=200,\n#      min_score_thresh=.5,\n#      agnostic_mode=False,\n#)\nplt.figure(figsize=(6,6))\nplt.imshow(image_np_with_detections)\nplt.show()\nplt.savefig('Predicted_360_SSD_ResNet50_V1_FPN_640x640.jpeg')\n\n#ax = plt.gca()\n#fig, ax = plt.subplots()\n#ax.imshow(image_np_with_detections)\n#for i in detections['detection_boxes'][0].numpy():\n#    rect = patches.Rectangle((i[0]*512,i[1]*512), (i[2]-i[0])*512 , (i[3]-i[1])*512, linewidth=1, edgecolor='r', facecolor='none')\n#    ax.add_patch(rect)\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-27T16:37:31.987527Z","iopub.execute_input":"2021-11-27T16:37:31.987787Z","iopub.status.idle":"2021-11-27T16:37:32.999736Z","shell.execute_reply.started":"2021-11-27T16:37:31.987758Z","shell.execute_reply":"2021-11-27T16:37:32.999063Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"pred = []\ntest_images_list = os.listdir('../input/bccd-dataset/BCCD/JPEGImages')\nprint(len(test_images_list))\n#print(test_images_list)\n# Doing though each image\nj = 0\nfor file_path in (test_images_list):\n    print(j)\n    if(j<300):\n        j+=1\n        continue\n    img = cv2.imread('../input/bccd-dataset/BCCD/JPEGImages/' + file_path)\n    \n    width,height,_ = img.shape\n    image_np = load_image_into_numpy_array('../input/bccd-dataset/BCCD/JPEGImages/' + file_path)\n    input_tensor = tf.convert_to_tensor(\n    np.expand_dims(image_np, 0), dtype=tf.float32)\n    outputs, predictions_dict, shapes = detect_fn(input_tensor)\n    #print(outputs['detection_boxes'][0][0])\n    #print(outputs['detection_classes'][0][0])\n    #print(outputs['detection_scores'][0][0])\n    #break\n    #outputs = predictor(img)\n    image_path, image_file_name = os.path.split(file_path)\n    #image_id = int(image_file_name.split(\".\")[0])+1\n    i = 0\n    for boxes in outputs['detection_boxes'][0]:\n        if(outputs['detection_scores'][0][i].numpy().tolist() > 0.35):\n            # Converting thr bounding boxes from (x1, y1, x2, y2) to (x, y, w, h)\n            boxes = boxes.numpy().tolist()\n            preprocessed_box = [boxes[0]*height, boxes[1]*width, abs(boxes[0] - boxes[2])*height, abs(boxes[1] - boxes[3])*width]\n            pred.append({\n                \"image_id\": file_path,\n                \"category_id\": outputs['detection_classes'][0][i].numpy().tolist(),\n                \"bbox\": preprocessed_box,\n                \"score\":outputs['detection_scores'][0][i].numpy().tolist()\n            })\n        i+=1\n    j+=1","metadata":{"execution":{"iopub.status.busy":"2021-11-27T16:24:10.447124Z","iopub.execute_input":"2021-11-27T16:24:10.447866Z","iopub.status.idle":"2021-11-27T16:25:09.521560Z","shell.execute_reply.started":"2021-11-27T16:24:10.447822Z","shell.execute_reply":"2021-11-27T16:25:09.520602Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"#pred","metadata":{"execution":{"iopub.status.busy":"2021-11-27T16:26:41.346644Z","iopub.execute_input":"2021-11-27T16:26:41.346938Z","iopub.status.idle":"2021-11-27T16:26:41.352927Z","shell.execute_reply.started":"2021-11-27T16:26:41.346904Z","shell.execute_reply":"2021-11-27T16:26:41.352227Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"import json\nwith open('predictions_ssd_resnet_50.json', 'w') as f:\n    json.dump(pred, f)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T16:27:53.525265Z","iopub.execute_input":"2021-11-27T16:27:53.525940Z","iopub.status.idle":"2021-11-27T16:27:53.551861Z","shell.execute_reply.started":"2021-11-27T16:27:53.525898Z","shell.execute_reply":"2021-11-27T16:27:53.551187Z"},"trusted":true},"execution_count":48,"outputs":[]}]}